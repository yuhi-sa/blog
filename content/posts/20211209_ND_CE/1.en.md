---
title: "Derivation of closed-form expression for cross-entropy between Gaussian distributions"
date: 2021-12-09T11:00:23+09:00
draft: false
tags: ["MachineLearning "] 
---
<!--more-->
# Derivation of closed-form expression for cross-entropy between Gaussian distributions
## Preparation
- Gaussian distribution
$$ 
p(x|\mu,\sigma)=\frac{1}{\sqrt{2\pi }}\exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}
$$
- Expected value

$$\mathbb{E}[x]=\mu$$
- Variance

$$\mathbb{E}[x^2]=\mu^2+\sigma^2$$
$$\mathbb{V}[x]=\mathbb{E}[x^2]-(\mathbb{E}[x]^2)$$

## Derivation
$$-\int_x p_1(x|\mu_1,\sigma_1)\log p_2(x|\mu_2,\sigma_2)dx$$

$$=-\mathbb{E}_{p1}[\log(\frac{1}{\sigma_2 \sqrt{2\pi}}\exp\{-\frac{1}{2}(\frac{x-\mu_2}{\sigma_2})^2\})]$$

$$=-\mathbb{E}_{p1}[-\log\sigma_2\sqrt{2\pi}-\frac{1}{2}(\frac{x-\mu_2}{\sigma_2})^2]$$

$$=\log\sigma_2\sqrt{2\pi}+\frac{1}{2}\mathbb{E}_{p1}(x-\mu_2)^2$$

$$=\log\sigma_2\sqrt{2\pi}+\frac{1}{2\sigma_2^2}(
\mathbb{E}[x^2]-2\mu_2\mathbb{E}[x]+\mathbb{E}[\mu_2^2])$$

$$=\log\sigma_2\sqrt{2\pi}+\frac{1}{2\sigma_2^2}(
\sigma_1^2+\mu_1^2-2\mu_1\mu_2+\mu_2^2)$$

$$=\log\sigma_2\sqrt{2\pi}+\frac{(\mu_1-\mu_2)^2+\sigma_1^2}{2\sigma_2^2}$$
