---
title: "Code description of ROS package to make op3 acquire walking using reinforcement learning"
date: 2021-11-02T10:17:23+09:00
draft: false
tags: ["Others"] 
---
<!--more-->
# Introduction  
ROS package for ROBOTIS OP3 to acquire walking using reinforcement learning
- [op3_walk](https://github.com/yuhi-sa/op3_walk)

# Result Video
- [op3_controller_demo](https://github.com/yuhi-sa/op3_walk/blob/main/docs/op3_controller_demo.mp4)

# Methods
This package uses deep reinforcement learning (DQN).  
The action value function is defined as a three-layer neural network (NN), and the Q-value is updated as follows  

$Q(s_t,a_t) = Q(s_t,a_t) + \eta(R_{t+1)} + \gamma \max_a Q(s_{t+1},a) - Q(s_t,a_t)$

The neural network is updated by back propagation using the loss function L.

$ L = \mathbb{E}(R_{t+1} + \gamma \max Q(s_{t+1},a_t)- Q(s_t,a_t))$

# Program
## [function.py](https://github.com/yuhi-sa/op3_walk/blob/main/scripts/function.py) and [motion.py](https://github.com/yuhi-sa/op3_walk/blob/main/scripts/motion.py)
[function] contains the definition of the agent.   
The Agent class has a Brain class that defines the neural network.   
With the actions and states stored in the ReplayMemory class, Brain calculates and updates the loss.  
The actions are discretized, and epsilon-greedy selection is made among the actions defined in [motion].
  
I used the code from this book as a reference.
- [Deep-Reinforcement-Learning-Book](https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book)

## [learning.py](https://github.com/yuhi-sa/op3_walk/blob/main/scripts/learning.py)
Input the state subscribed from [controller] to the Agent, calculate the action, and publish it.     
This one uses pytorch to define the neural network, so it needs to be run in python3.

## [controller.py](https://github.com/yuhi-sa/op3_walk/blob/main/scripts/controller.py)  
[controller]. It subscribes to actions published by [learning] and actually runs op3.
Then publish the state.    
Due to the op3 package, you will need to run this in python2.

# Learning curve
Learning curve for walking distance

![歩行距離](https://github.com/yuhi-sa/op3_walk/blob/main/docs/learning.png?raw=true)
