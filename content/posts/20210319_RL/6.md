---
title: Advantage Actor Critic(A2C)
date: 2021-03-22T11:30:23+09:00
draft: false
tags: ["Pythonで学ぶ強化学習"] 
---
<!--more-->
状態における行動価値$Q(s,a)$は，状態そのものへの依存度が大きい傾向がある．そこで状態の価値$V(s)$を差し引いたうえで行動を評価することを考える．

$$A(s,a)=Q(s,a)-V(s)$$

この$A(s,a)$をAdvantageと呼ぶ．
Advantageを利用する場合の方策勾配は以下のようになる．

$$\nabla J(\theta) = E_{\pi_{\theta}}[\nabla \log \pi_{\theta(a|s)}A(s,a)]$$

$\pi_\theta(a|s)$をActor，Advantageの計算に必要な$V(s)$をCriticとしてActor Critic法を使用することができる．
これをAdvantage Actor Critic(A2C)と呼ぶ．

# 参考
久保隆宏,"[Pythonで学ぶ強化学習 入門から実践まで](https://amzn.to/3tA1S4W)"